{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9L4FYjkqUM5",
        "colab_type": "code",
        "outputId": "736ab76f-1fd8-4de4-a488-d1e0be7978f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX_IvPs6qgQS",
        "colab_type": "code",
        "outputId": "634688c1-d0e1-4807-9204-179decf03a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5856ZM9Lqzpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataTrain = pd.read_csv('finalcleandata.csv')\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000, lower=True)\n",
        "\n",
        "dataTrain = dataTrain['message']\n",
        "\n",
        "xtrain = tokenizer.fit_on_texts(dataTrain)\n",
        "xfinal = tokenizer.texts_to_sequences(dataTrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acv8aqiaq53O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "dictionary = dict()\n",
        "data = open(\"/content/drive/My Drive/glove.twitter.27B.200d.txt\",encoding='utf8')\n",
        "for line in data:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    try:\n",
        "        coefs = np.asarray(values[1:],dtype='float32')\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    dictionary[word] = coefs\n",
        "data.close()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXSVPZelxcBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = {k: (v+3) for (k, v) in dictionary.items()}\n",
        "dictionary[\"<PAD>\"] = 0  # actual zero - means they are like multiplied by 0\n",
        "dictionary[\"b'\"] = 1\n",
        "dictionary[\"<UNK>\"] = 2\n",
        "dictionary[\"<UNUSED>\"] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Bmjz_A4RsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD = 0  # a hyperparameter\n",
        "xtrain_modified = keras.preprocessing.sequence.pad_sequences(\n",
        "    xfinal, value=PAD, padding='post', maxlen=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWDCPo4P7ZL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataTrain = pd.read_csv('finalcleandata.csv')\n",
        "# ytrain1 = dataTrain[['toxic','severe_toxic','obscene','threat','insult','identity_hate']] \n",
        "ytrain1 = dataTrain['toxic']\n",
        "ytrain2 = dataTrain['obscene']\n",
        "ytrain3 = dataTrain['insult']\n",
        "ytrain4 = dataTrain['racism']\n",
        "ytrain5 = dataTrain['sexism']\n",
        "\n",
        "xt = xtrain_modified[:10000] \n",
        "xv = xtrain_modified[10000:] \n",
        "\n",
        "yt1 = ytrain1[:10000]\n",
        "yv1 = ytrain1[10000:] \n",
        "\n",
        "yt2 = ytrain2[:10000]\n",
        "yv2 = ytrain2[10000:] \n",
        "\n",
        "yt3 = ytrain3[:10000]\n",
        "yv3 = ytrain3[10000:] \n",
        "\n",
        "yt4 = ytrain4[:10000]\n",
        "yv4 = ytrain4[10000:] \n",
        "\n",
        "yt5 = ytrain5[:10000]\n",
        "yv5 = ytrain5[10000:] \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgRbzgo37GJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_hate():\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Embedding(10000, 200))\n",
        "  model.add(keras.layers.GlobalAveragePooling1D())\n",
        "  model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "  model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxSlg6cB7J0I",
        "colab_type": "code",
        "outputId": "c3a52fee-cf28-48de-b271-3150305c762c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model=model_hate()\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 200)         2000000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                3216      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 2,003,233\n",
            "Trainable params: 2,003,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcuU_ns579_h",
        "colab_type": "code",
        "outputId": "eb0b0570-6b7c-44cc-8048-8945d90f6d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "print(\"TOXIC\")\n",
        "history = model.fit(xt,yt1,epochs=2,batch_size=128,validation_data=(xv,yv1))\n",
        "print(\"OBSCENE\")\n",
        "history = model.fit(xt,yt2,epochs=2,batch_size=128,validation_data=(xv,yv2))\n",
        "print(\"INSULT\")\n",
        "history = model.fit(xt,yt3,epochs=2,batch_size=128,validation_data=(xv,yv3))\n",
        "print(\"RACISM\")\n",
        "history = model.fit(xt,yt4,epochs=2,batch_size=128,validation_data=(xv,yv4))\n",
        "print(\"SEXISM\")\n",
        "history = model.fit(xt,yt5,epochs=2,batch_size=128,validation_data=(xv,yv5))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOXIC\n",
            "Train on 10000 samples, validate on 4046 samples\n",
            "Epoch 1/2\n",
            "10000/10000 [==============================] - 3s 337us/sample - loss: 0.6036 - acc: 0.7003 - val_loss: 0.5401 - val_acc: 0.7217\n",
            "Epoch 2/2\n",
            "10000/10000 [==============================] - 3s 290us/sample - loss: 0.4619 - acc: 0.7680 - val_loss: 0.4004 - val_acc: 0.8307\n",
            "OBSCENE\n",
            "Train on 10000 samples, validate on 4046 samples\n",
            "Epoch 1/2\n",
            "10000/10000 [==============================] - 3s 287us/sample - loss: 0.3124 - acc: 0.8658 - val_loss: 0.3046 - val_acc: 0.8759\n",
            "Epoch 2/2\n",
            "10000/10000 [==============================] - 3s 276us/sample - loss: 0.2508 - acc: 0.8968 - val_loss: 0.2818 - val_acc: 0.8972\n",
            "INSULT\n",
            "Train on 10000 samples, validate on 4046 samples\n",
            "Epoch 1/2\n",
            "10000/10000 [==============================] - 3s 281us/sample - loss: 0.2505 - acc: 0.8976 - val_loss: 0.2724 - val_acc: 0.8910\n",
            "Epoch 2/2\n",
            "10000/10000 [==============================] - 3s 282us/sample - loss: 0.2160 - acc: 0.9121 - val_loss: 0.2740 - val_acc: 0.8883\n",
            "RACISM\n",
            "Train on 10000 samples, validate on 4046 samples\n",
            "Epoch 1/2\n",
            "10000/10000 [==============================] - 3s 282us/sample - loss: 0.5686 - acc: 0.8041 - val_loss: 0.3817 - val_acc: 0.8497\n",
            "Epoch 2/2\n",
            "10000/10000 [==============================] - 3s 283us/sample - loss: 0.3342 - acc: 0.8583 - val_loss: 0.3067 - val_acc: 0.8547\n",
            "SEXISM\n",
            "Train on 10000 samples, validate on 4046 samples\n",
            "Epoch 1/2\n",
            "10000/10000 [==============================] - 3s 291us/sample - loss: 0.4310 - acc: 0.8456 - val_loss: 0.3742 - val_acc: 0.8502\n",
            "Epoch 2/2\n",
            "10000/10000 [==============================] - 3s 295us/sample - loss: 0.3656 - acc: 0.8466 - val_loss: 0.3407 - val_acc: 0.8515\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}